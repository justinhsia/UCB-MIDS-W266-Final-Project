{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Toxicity_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcymyTO2SrHW",
        "colab_type": "text"
      },
      "source": [
        "# 0. Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV5dqaJMSrHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkPdYwEqSrHc",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ylf4Ii4wSrHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the training dataset\n",
        "\n",
        "data_path = 'new_train.csv'\n",
        "data_raw = pd.read_csv(data_path)\n",
        "\n",
        "print(\"Number of rows in data =\",data_raw.shape[0])\n",
        "print(\"Number of columns in data =\",data_raw.shape[1])\n",
        "print(\"\\n\")\n",
        "print(\"**Sample data:**\")\n",
        "data_raw.drop(columns='index', inplace=True)\n",
        "data_raw.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paU026YvSrHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show total number of comments for each label\n",
        "\n",
        "categories = list(data_raw.columns.values)\n",
        "\n",
        "sns.set(font_scale = 2)\n",
        "plt.figure(figsize=(15,8))\n",
        "ax = sns.barplot(categories[2:], data_raw.iloc[:,2:].sum().values)\n",
        "plt.title(\"Comments in each category\", fontsize=24)\n",
        "plt.ylabel('Number of comments', fontsize=18)\n",
        "plt.xlabel('Comment Type ', fontsize=18)\n",
        "\n",
        "#adding the text labels\n",
        "\n",
        "rects = ax.patches\n",
        "labels = data_raw.iloc[:,2:].sum().values\n",
        "for rect, label in zip(rects, labels):\n",
        "    height = rect.get_height()\n",
        "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize=18)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC2ntrP6SrHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Counting the number of comments having multiple labels\n",
        "\n",
        "rowSums = data_raw.iloc[:,2:].sum(axis=1)\n",
        "multiLabel_counts = rowSums.value_counts()\n",
        "multiLabel_counts = multiLabel_counts.iloc[1:]\n",
        "sns.set(font_scale = 2)\n",
        "plt.figure(figsize=(15,8))\n",
        "ax = sns.barplot(multiLabel_counts.index, multiLabel_counts.values)\n",
        "plt.title(\"Comments having multiple labels \")\n",
        "plt.ylabel('Number of comments', fontsize=18)\n",
        "plt.xlabel('Number of labels', fontsize=18)\n",
        "\n",
        "#adding the text labels\n",
        "rects = ax.patches\n",
        "labels = multiLabel_counts.values\n",
        "for rect, label in zip(rects, labels):\n",
        "    height = rect.get_height()\n",
        "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ68zZu4SrHs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9dbbef20-a172-46c0-afe6-5eeeda30db2e"
      },
      "source": [
        "# Generate a summary column \"category\".  The column contains \"1\" if the comment is labeled at least once.\n",
        "# Otherwise, the column will take on a value of \"0\".\n",
        "\n",
        "data_raw[\"category\"] = data_raw.iloc[:,2:8].sum(axis=1)\n",
        "data_raw[\"category\"] = data_raw[\"category\"]/data_raw[\"category\"]\n",
        "data_raw.fillna(0, inplace=True)\n",
        "data_raw.category = data_raw.category.astype(int)\n",
        "data_raw.head()\n",
        "print(\"Total number of labeled comments is %d.\" %data_raw.category.sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of labeled comments is 14602.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oskg9KGHSrHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnwyS39WSrHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Pre-processing\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import re\n",
        "import sys\n",
        "import warnings\n",
        "\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "\n",
        "def cleanHtml(sentence):\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
        "    return cleantext\n",
        "\n",
        "def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n",
        "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
        "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
        "    cleaned = cleaned.strip()\n",
        "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
        "    return cleaned\n",
        "\n",
        "def keepAlpha(sentence):\n",
        "    alpha_sent = \"\"\n",
        "    for word in sentence.split():\n",
        "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
        "        alpha_sent += alpha_word\n",
        "        alpha_sent += \" \"\n",
        "    alpha_sent = alpha_sent.strip()\n",
        "    return alpha_sent\n",
        "\n",
        "data['comment_text'] = data['comment_text'].str.lower()\n",
        "data['comment_text'] = data['comment_text'].apply(cleanHtml)\n",
        "data['comment_text'] = data['comment_text'].apply(cleanPunc)\n",
        "data['comment_text'] = data['comment_text'].apply(keepAlpha)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFoX_xotSrH2",
        "colab_type": "text"
      },
      "source": [
        "# 2. Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i2KgXB3SrH2",
        "colab_type": "text"
      },
      "source": [
        "The rest of the code is adopted to work with the Coursera code.\n",
        "\n",
        "DO NOT USE THIS CODE WITH OTHER EMBEDDINGS OR MODELS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7ImhyzgSrH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Retain relevant columns from the preprocessed dataset.\n",
        "data = data[['id', 'comment_text', 'category']]\n",
        "\n",
        "# Replace values in the column 'toxicity' by {0: non-toxic, 1: toxic}.\n",
        "data.loc[data.category == 0, 'category'] = 'non-toxic'\n",
        "data.loc[data.category == 1, 'category'] = 'toxic'\n",
        "\n",
        "# Replace index in-place by the 'id' column.\n",
        "data.set_index('id', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCaxijptSrH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13WKvaEQSrH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.category.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmU84sNiSrH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From here on, code is adopted from the Coursera tutorial."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtUgvhchSrIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "possible_labels = data.category.unique()\n",
        "possible_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW-_NjlGSrID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dict = {}\n",
        "\n",
        "for index, possible_labels in enumerate(possible_labels):\n",
        "    label_dict[possible_labels] = index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCaXVBUHSrIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px_wlVpjSrIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['label'] = data.category.replace(label_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "717XtXg4SrIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmfpBeSSSrIM",
        "colab_type": "text"
      },
      "source": [
        "# 3. Training / Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mCyzm3VSrIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_aEFfcNSrIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    data.index.values,\n",
        "    data.label.values,\n",
        "    test_size = 0.9,\n",
        "    random_state = 42,\n",
        "    stratify = data.label.values\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnlBhRIaSrIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['data_type'] = ['not_set']*data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phgdVmIbSrIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.loc[X_train, 'data_type'] = 'train'\n",
        "data.loc[X_val, 'data_type'] = 'val'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQBnY86RSrIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.groupby(['category', 'label', 'data_type']).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0dzZqLiSrIZ",
        "colab_type": "text"
      },
      "source": [
        "# 4. Load Tokenizer and Encode Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwdaLNgxUtLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uinO8VeuSrIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL_lenuMSrIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    do_lower_case = True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1XpM9V9SrIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length = 200\n",
        "\n",
        "encode_data_train = tokenizer.batch_encode_plus(\n",
        "    data[data.data_type == 'train'].comment_text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=max_length,\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encode_data_val = tokenizer.batch_encode_plus(\n",
        "    data[data.data_type == 'val'].comment_text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=max_length,\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_train = encode_data_train['input_ids']\n",
        "attention_masks_train = encode_data_train['attention_mask']\n",
        "labels_train = torch.tensor(data[data.data_type == 'train'].label.values)\n",
        "\n",
        "input_ids_val = encode_data_val['input_ids']\n",
        "attention_masks_val = encode_data_val['attention_mask']\n",
        "labels_val = torch.tensor(data[data.data_type == 'val'].label.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMP_Uia_SrIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example encoding.  Note that each wordpiece is encoded with an unique ID and\n",
        "# the entire sentence is padded to a maximum length of 'max_length'.\n",
        "encode_data_train['input_ids'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-4aRVjWSrIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fnsw1U0iSrIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note the ratio of validation set to the whole data set is the same as the 'stratify' parameter set\n",
        "# 'train_test_split'.\n",
        "\n",
        "len(dataset_val)/(len(dataset_val)+len(dataset_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlAvTzAnSrIm",
        "colab_type": "text"
      },
      "source": [
        "# 5. Setup BERT Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eSOsofwSrIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNBbHUhCSrIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is the fine-tuning step!!!\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=len(label_dict),\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEYwlk7XSrIq",
        "colab_type": "text"
      },
      "source": [
        "# 6. Create Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fskqKnXSrIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKHPDjn9SrIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    sampler=RandomSampler(dataset_train),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "dataloader_val = DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=RandomSampler(dataset_val),\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RhPnAdkSrIu",
        "colab_type": "text"
      },
      "source": [
        "# 7. Setup Optimizer and Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_3D_PnvSrIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyyF7EGxSrIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is from HuggingFace.\n",
        "\n",
        "# AdamW is to optimizer our backpropagation.\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=2e-5, # 2e-5 > 5e-5\n",
        "    eps=1e-8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmVW7At6SrIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 4\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=len(dataloader_train)*epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyaXFh5CSrI0",
        "colab_type": "text"
      },
      "source": [
        "# 8. Define Performance Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ac2XrMlSrI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMZ9dKvnSrI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# f1 score is better because there is class inbalance.\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels = labels.flatten()\n",
        "    return f1_score(labels, preds_flat, average='weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH01ZN-JSrI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vcws2WdSrI8",
        "colab_type": "text"
      },
      "source": [
        "# 9. Create Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEo42LIQSrI9",
        "colab_type": "text"
      },
      "source": [
        "This approach is adapted from an older version of HuggingFace's `run_glue.py` script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_XHir4CSrI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)  # this has to do with using GPUs."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-qwcnrdixxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB_pfpsuSrI_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e655ec6-6e93-4847-f453-393115b2876b"
      },
      "source": [
        "# Determine which device is used, cuda (GPS) vs. cpu.\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCsu44FfSrJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluation Function\n",
        "\n",
        "def evaluate(dataloader_val):\n",
        "    \n",
        "    model.eval()  # Put model in evaluation mode, which freezes all weights.\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':       batch[0],\n",
        "                 'attention_mask': batch[1],\n",
        "                 'labels':          batch[2],\n",
        "                }\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "        \n",
        "        logits = logits.detach().cpu().numpy()  # In the case of using GPU, the number will be pulled off to CPU.\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "        \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "    \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJYSK1kJSrJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Loop\n",
        "\n",
        "training_loss_tracker = []\n",
        "val_loss_tracker = []\n",
        "val_f1_tracker = []\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    \n",
        "    model.train()  # set the model to training mode\n",
        "    \n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train,\n",
        "                        desc='Epoch {:1d}'.format(epoch),\n",
        "                        leave=False,\n",
        "                        disable=False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        \n",
        "        model.zero_grad()\n",
        "    \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {\n",
        "            'input_ids':      batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'labels':         batch[2]\n",
        "        }\n",
        "        \n",
        "        outputs = model(**inputs)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()  # Backpropagation.  'loss' is a built-in function in BERT.\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "        \n",
        "        \n",
        "    torch.save(model.state_dict(), f'BERT_S_L{max_length}_B{batch_size}_E{epoch}.model')\n",
        "    \n",
        "    tqdm.write(f'\\nEpoch {epoch}')\n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    \n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    \n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
        "    \n",
        "    training_loss_tracker.append(loss_train_avg)\n",
        "    val_loss_tracker.append(val_loss)\n",
        "    val_f1_tracker.append(val_f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IbgV-6vgnC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training_loss_tracker\n",
        "# val_loss_tracker\n",
        "val_f1_tracker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhOrERBOSrJH",
        "colab_type": "text"
      },
      "source": [
        "# 10. Load and Evaluate Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HudUdAvcM9t3",
        "colab_type": "text"
      },
      "source": [
        "Load and process the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnGfwktCNGmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the test dataset\n",
        "\n",
        "data_path = 'new_test.csv'\n",
        "data_raw = pd.read_csv(data_path)\n",
        "\n",
        "print(\"Number of rows in data =\",data_raw.shape[0])\n",
        "print(\"Number of columns in data =\",data_raw.shape[1])\n",
        "print(\"\\n\")\n",
        "print(\"**Sample data:**\")\n",
        "data_raw.drop(columns='index', inplace=True)\n",
        "data_raw.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf-RDltcNPk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show total number of comments for each label\n",
        "\n",
        "categories = list(data_raw.columns.values)\n",
        "\n",
        "sns.set(font_scale = 2)\n",
        "plt.figure(figsize=(15,8))\n",
        "ax = sns.barplot(categories[2:], data_raw.iloc[:,2:].sum().values)\n",
        "plt.title(\"Comments in each category\", fontsize=24)\n",
        "plt.ylabel('Number of comments', fontsize=18)\n",
        "plt.xlabel('Comment Type ', fontsize=18)\n",
        "\n",
        "#adding the text labels\n",
        "\n",
        "rects = ax.patches\n",
        "labels = data_raw.iloc[:,2:].sum().values\n",
        "for rect, label in zip(rects, labels):\n",
        "    height = rect.get_height()\n",
        "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize=18)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuodrKlvNV0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Counting the number of comments having multiple labels\n",
        "\n",
        "rowSums = data_raw.iloc[:,2:].sum(axis=1)\n",
        "multiLabel_counts = rowSums.value_counts()\n",
        "multiLabel_counts = multiLabel_counts.iloc[1:]\n",
        "sns.set(font_scale = 2)\n",
        "plt.figure(figsize=(15,8))\n",
        "ax = sns.barplot(multiLabel_counts.index, multiLabel_counts.values)\n",
        "plt.title(\"Comments having multiple labels \")\n",
        "plt.ylabel('Number of comments', fontsize=18)\n",
        "plt.xlabel('Number of labels', fontsize=18)\n",
        "\n",
        "#adding the text labels\n",
        "rects = ax.patches\n",
        "labels = multiLabel_counts.values\n",
        "for rect, label in zip(rects, labels):\n",
        "    height = rect.get_height()\n",
        "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4pdsZiRNkvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate a summary column \"category\".  The column contains \"1\" if the comment is labeled at least once.\n",
        "# Otherwise, the column will take on a value of \"0\".\n",
        "\n",
        "data_raw[\"category\"] = data_raw.iloc[:,2:8].sum(axis=1)\n",
        "data_raw[\"category\"] = data_raw[\"category\"]/data_raw[\"category\"]\n",
        "data_raw.fillna(0, inplace=True)\n",
        "data_raw.category = data_raw.category.astype(int)\n",
        "data_raw.head()\n",
        "print(\"Total number of labeled comments is %d.\" %data_raw.category.sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G54g2JdsNps3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = data_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYMlQyYYN6MG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Pre-processing\n",
        "\n",
        "test_data['comment_text'] = test_data['comment_text'].str.lower()\n",
        "test_data['comment_text'] = test_data['comment_text'].apply(cleanHtml)\n",
        "test_data['comment_text'] = test_data['comment_text'].apply(cleanPunc)\n",
        "test_data['comment_text'] = test_data['comment_text'].apply(keepAlpha)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZJqsZP2NWll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Retain relevant columns from the preprocessed dataset.\n",
        "test_data = test_data[['id', 'comment_text', 'category']]\n",
        "\n",
        "# Replace values in the column 'toxicity' by {0: non-toxic, 1: toxic}.\n",
        "test_data.loc[test_data.category == 0, 'category'] = 'non-toxic'\n",
        "test_data.loc[test_data.category == 1, 'category'] = 'toxic'\n",
        "\n",
        "# Replace index in-place by the 'id' column.\n",
        "test_data.set_index('id', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5IaJQjBOgi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wcg33UiiOgTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data.category.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS7afXj5PIyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data['label'] = test_data.category.replace(label_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekdlxIT1PIlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data[test_data['category'] == 'toxic'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nRNihglQQlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encode_data_test = tokenizer.batch_encode_plus(\n",
        "    test_data.comment_text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=max_length,\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFt4ZcnPQRC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids_test = encode_data_test['input_ids']\n",
        "attention_masks_test = encode_data_test['attention_mask']\n",
        "labels_test = torch.tensor(test_data.label.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbokT7p7QRQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiXPnoNsQQ3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloader_test = DataLoader(\n",
        "    dataset_test,\n",
        "    sampler=RandomSampler(dataset_test),\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4SZRFmpSrJI",
        "colab_type": "text"
      },
      "source": [
        "The model in this section needs to be trained in Colab using GPU from step 9.  In the training loop line 40, save the model with appropriate names.  Here is the convention:\n",
        "\n",
        "> BERT_X_L###_B####_E#.model\n",
        "\n",
        "> X     : S or M for single class or multi-class\n",
        "\n",
        "> L###  : maximum length of each tokenized comment_text (from Section 4)\n",
        "\n",
        "> B#### : batch size used in the training loop (from Section 6)\n",
        "\n",
        "> E#    : epoch number when the model is trained (from Section 7)\n",
        "\n",
        "Example:\n",
        "\n",
        "> BERT_S_L256_B1024_E2.model is a model trained with single class, a maximum length of 256 tokens, a batch size of 1024, and on the second epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAWIFa0vSrJI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "eab2872f-d88a-42bf-8d48-f8706d302c9a"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
        "                                                      num_labels=len(label_dict),\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hZS4wOmSrJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.to(device)\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNsCimT4SrJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model name would be different.  Try running traning on Google Colab using GPUs.\n",
        "\n",
        "model.load_state_dict(\n",
        "    torch.load('/content/BERT_S_L200_B32_E2.model',\n",
        "               map_location=torch.device(device)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRHq-_i1SrJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, predictions, true_vals = evaluate(dataloader_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9dNCEJuSrJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}